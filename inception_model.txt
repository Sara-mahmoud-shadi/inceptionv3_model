import os
import cv2
import pandas as pd
import matplotlib.pyplot as pl
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense,Flatten,Dropout,BatchNormalization,Conv2D,MaxPool2D,Input,Activation,MaxPooling2D,AveragePooling2D,GlobalAveragePooling2D
from keras import optimizers
from tensorflow.keras.callbacks import EarlyStopping
import tensorflow as tf
from keras.utils.np_utils import to_categorical
from keras import layers
from keras import backend as K
from keras.applications.imagenet_utils import decode_predictions
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import seaborn as sns
import keras

path_train='../input/data-com/train_images/train_images'
path_test='../input/data-com/test_images/test_images'
path_label='../input/label/train (2).csv'
df= pd.read_csv('../input/label/train (2).csv')
x_train=[]
y_train=[]
x_test=[]
size_shape=[]
width,hight=150,150
epoch=100
num_of_classes = 6
batch_size = 64

data=['buildings' ,'forest','glacier','mountain','sea','street']

#get image shape

for i in os.listdir(path_train):
    
    im=cv2.imread(path_train+'/'+i)
    size_shape.append(im.shape)
pd.Series(size_shape).value_counts()

#Read Images From Data Sets (Training)

for i in os.listdir(path_train):
    img_label = getImgLabel(i)
    im=cv2.imread(path_train+'/'+i)
    image=cv2.resize(im,(width,hight))
    x_train.append(image)
    y_train.append(img_label)

#Read Images From Data Sets (Testing)

x_test = []
X_imgs = []
for file in os.listdir(path_test) : 
    
    X_imgs.append(file)
    image_path = os.path.join(path_test, file)
    image = cv2.imread(image_path)
    image_array = cv2.resize(image , (width,hight))
    x_test.append(image_array)
print(f'we have {len(x_test)} items in X TEST')


#Convert Variables From Data Frame Into Array

x_train=np.array(x_train)
y_train=np.array(y_train)
x_test=np.array(x_test)
print("x_train is",x_train.shape)
print("y_train is",y_train.shape)
print("x_test is",x_test.shape)

#check the balance of the data

sns.countplot(x = "label" , data = df)
df['label'].value_counts()

#Divide the data into Train and Validation

x,x_val,y,y_val=train_test_split(x_train,y_train,test_size=.2,random_state=0) 

#Apply DataAugmantetion

datagen = ImageDataGenerator(
 rotation_range=0, # randomly rotate images in the range (degrees, 0 to 180)
 zoom_range = 0.1, # Randomly zoom image 
 width_shift_range=0.1, # randomly shift images horizontally fraction of total width)
 height_shift_range=0.1, # randomly shift images vertically (fraction of total height)
 horizontal_flip=True, # randomly flip images) 

datagen.fit(x_train)

#Create Function Convolution Layers

def conv2d_bn(x,filters,num_row,num_col,padding='same',strides=(1, 1),name=None):
    if name is not None:
        bn_name = name + '_bn'
        conv_name = name + '_conv'
    else:
        bn_name = None
        conv_name = None
    if K.image_data_format() == 'channels_first':
        bn_axis = 1
    else:
        bn_axis = 3
        x = Conv2D(filters, (num_row, num_col),strides=strides,padding=padding)(x)
        x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)
        x = Activation('relu', name=name)(x)
    return x

#Using Model InceptionV3

def InceptionV3(classes=6):
 
    img_input = Input(shape=(width,hight,3))
    if K.image_data_format() == 'channels_first':
        channel_axis = 1
    else:
        channel_axis = 3
    x = conv2d_bn(img_input, 32, 2, 2, strides=(2,2), padding='valid')
    x = conv2d_bn(x, 32, 3, 3, padding='valid')
    x=  BatchNormalization()(x)
    x = conv2d_bn(x, 64, 3, 3)
    x = MaxPooling2D((3, 3), strides=(2, 2))(x)
    x = conv2d_bn(x, 80, 1, 1, padding='valid')
    x = conv2d_bn(x, 192, 3, 3, padding='valid')
    x = MaxPooling2D((3, 3), strides=(2, 2))(x)
    
 # Architecture Inception

    for i in range(2):
        branch1x1 = conv2d_bn(x, 320, 1, 1)
        
        branch3x3 = conv2d_bn(x, 384, 1, 1)
        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)
        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)
        branch3x3 = layers.concatenate([branch3x3_1, branch3x3_2], axis=channel_axis,name='mixed9_' + str(i))
        
        branch3x3dbl = conv2d_bn(x, 448, 1, 1)
        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)
        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)
        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)
        branch3x3dbl = layers.concatenate([branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)
       
        branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)
        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)
        x = layers.concatenate([branch1x1, branch3x3, branch3x3dbl, branch_pool],axis=channel_axis)
 
 # Classification block
        x = GlobalAveragePooling2D(name='avg_pool')(x)
        x = Dense(num_of_classes, activation='softmax',name='predictions')(x)
 
        inputs = img_input
 # Create model.
        model = Model(inputs=img_input, outputs=x, name='inception_v3')
 
        return model

model=InceptionV3()

print(model.summary())

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])

early_stoping= EarlyStopping(patience=10,restore_best_weights=True)
callbacks=[early_stoping]

#Learninig Model

history = model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),epochs = epoch,
                                   validation_data =(x_val,y_val), callbacks=callbacks)